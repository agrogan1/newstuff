---
title: "Interactions in Logistic Regression"
subtitle: "New Version"
author: "Andy Grogan-Kaylor"
date: "today"
format:
  html:
    toc: true
    number-sections: true
    theme:
      light: yeti
      dark: vapor
    lightbox: true
  pdf:
    toc: true
    toc-depth: 3
    number-sections: true
    colorlinks: true
bibliography: logistic-interactions-3.bib
nocite: |
  Ai2003, @KaracaMandic2012, @Mize2019
---

# Background

```{css, echo=FALSE}

blockquote {
  color: black;
  border-left: 2px solid #FFCB05; 
  padding: 0.5em 10px;
}
  
```

```{r}
#| echo: false
#| output: false

library(Statamarkdown)

```

The purpose of this tutorial is to illustrate the idea that in *logistic regression*, the $\beta$ parameter for an interaction term may not accurately characterize the underlying interactive relationships. 

This idea may be easier to describe if we recall the formula for a logistic regression: 

$$\ln\left(\frac{P(y)}{1 - P(y)}\right) = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_1 \times x_2$$ {#eq-logistic}

::: {.callout-warning collapse="false"}
In @eq-logistic, the sign, and statistical significance, of $\beta_3$ may not accurately characterize the underlying relationship.
:::


```{stata, echo=FALSE, message=FALSE, output=FALSE}

twoway (function y = .5*x, range(-10 10) lwidth(2)) ///
(function y = 2*x + 1, range(-10 10) lwidth(2)), ///
legend(order(1 "group 1" 2 "group 2")) ///
title("Demonstration of Interactive Relationships") ///
subtitle("In Linear Regression") ///
caption("A single parameter can capture the difference in slopes between the two groups") ///
name(linear, replace)

twoway (function y = exp(.5*x) / (1 + exp(.5*x)), range(-10 10) lwidth(2)) ///
(function y = exp(2*x + 1) / (1 + exp(2*x + 1)), range(-10 10) lwidth(2)), ///
legend(order(1 "group 1" 2 "group 2")) ///
title("Demonstration of Interactive Relationships") ///
subtitle("In Logistic Regression") ///
caption("No single parameter can capture the difference in slopes between the two groups") ///
name(logistic, replace)

graph combine linear logistic, rows(1) ysize(3) name(combined, replace)

graph export "combined.png", as(png) width(2000) name("combined") replace

```

![Demonstration of Interactive Relationships](combined.png){ width=90% }

::: {.callout-tip collapse="false"}
## Key Idea

In a *linear* model, a single parameter can capture the difference in slopes between the two groups. In a *non-linear* model, no single parameter can capture the difference in slopes between the two groups.
:::

::: {.callout-tip collapse="true"}
## Some Calculus (Not Essential To The Discussion)

Imagine a linear model: 

$$y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_1 \times x_2 + e_i$$

Here (following @Ai2003): 

$$\frac{\partial y}{\partial x_1 \partial x_2} = \beta_3$$ 

We use $\text{logit}$ to describe: 

$$\ln\left(\frac{P(y)}{1 - P(y)}\right)$$ 

In the logistic model, the quantity: 

$$\frac{\partial \text{logit} (y)}{\partial x_1 \partial x_2}$$ 

does not have such a straightforward solution, and--importantly for this discussion--is not simply equal to $\beta_3$.
:::

# Get The Data

We start by obtaining *simulated data* from StataCorp. 

```{stata, collectcode=TRUE}

clear all

graph close _all

use http://www.stata-press.com/data/r15/margex, clear

```

# Describe The Data
	
The variables are as follows:

```{stata}

describe

```

# Estimate Logistic Regression

We then run a logistic regression model in which `outcome` is the dependent variable. `age` and `group` are the independent variables. We estimate an interaction of `group` and `age`. 

> We note that the regression coefficient for the interaction terms are not statistically significant. 

```{stata, collectcode = TRUE}

logit outcome c.age##i.group

```

# Margins

We use the `margins` command to estimate predicted probabilities at different values of `group` and `age`. 

```{stata, collectcode = TRUE}

margins group, at(age = (20 30 40 50 60))

```

# Plotting Margins

`margins` provides a lot of results, which can be difficult to understand. Therefore, we use `marginsplot` to *plot* these `margins` results. 

> There certainly seems to be some kind of interaction of `group` and `age`.

```{stata}

marginsplot

graph export mymarginsplot.png, width(1000) replace
	
```

![Margins Plot](mymarginsplot.png){ width=75% } 	

# Rerun `margins`, `post`ing Results

We again employ the `margins` command, this time using the `post` option so that the results of the margins command are *posted* as an estimation result. This will allow us to employ the `test` command to statistically test different margins against each other. 

```{stata, collectcode = TRUE}

margins group, at(age = (20 30 40 50 60)) post

```

# `margins` with `coeflegend`

We follow up by using the `margins` command with the `coeflegend` option to see the way in which Stata has labeled the different margins. 

```{stata, collectcode = TRUE}

margins, coeflegend

```

# Testing Margins Against Each Other

Lastly, we test the margins at age 20 across some of the groups, and again at ages 50 and 60 for some of the groups. 

> We note that the original regression parameter for the interaction term was not statistically significant. Indeed, the margins at age 20 are not statistically significantly different by group (1 vs. 2), though they are close to being significantly different. However, at ages 50 & 60, there is a statistically significant difference by group (1 vs. 2). 

```{stata}

test _b[1bn._at#1bn.group] = _b[1bn._at#2.group] // groups 1 & 2 at age 20
	
test _b[4._at#1bn.group] = _b[4._at#2.group] // groups 1 & 2 at age 50

test _b[5._at#1bn.group] =  _b[5._at#2.group] // groups 1 & 2 at age 60

```










