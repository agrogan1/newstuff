---
title: "Very Large Constants, Coefficients, OR's or RR's or IRR's"
subtitle: "Possible causes and solutions"
author: "Andy Grogan-Kaylor"
date: "today"
format:
  html:
    toc: true
    number-sections: true
    anchor-sections: true
    theme:
      light: yeti
      dark: vapor
    lightbox: true
  pdf:
    toc: true
    number-sections: true
---

```{css}
#| echo: false

blockquote {
  background: #FFFFFF;
  color: #000000;
  border-left: 3px solid #FFCB05;
}

```

One sometimes sees *extremely large* $\beta$ coefficients, OR's or RR's or IRR's.

1. Is this due to very low *base rates* of one category of the outcome? Those can inflate coefficients, RR's, OR's, and IRR's.
2. What are the *units of the independent variables*? For example if your independent variable is a percentage expressed on a 0.0 to 1.0 scale, the scale of your independent variable can radically inflate your estimates for $\beta$. Re-scaling the independent variable sometimes helps.
3. Should some of your *continuous independent variables be centered*? Should you *collapse categories for some of your categorical independent variables*? 

::: {.callout-tip}
## What Does $\beta_0$ Mean?

Remember that the $\beta_0$ term is the mean outcome for an individual with a score of 0 on all of the independent variables. This may sometimes provide reasonable estimates, but it may sometimes be necessary to center some or all of your independent variables. If independent variables are not centered, $\beta_0$ may represent the value of the outcome for a combination of independent variables well outside of the data range. See the figure below for an illustration of this idea.
:::
    
```{r}
#| echo: false
#| label: fig-plot
#| fig-cap: "intercept outside range of observed data"
#| fig-height: 5

library(michigancolors)

# regression line

x <- seq(0, 10, .1) # random sequence of x's

y <- -1 * x + 5 # generate y

plot(x, y, 
     col = michigancolors("maize"),
     lwd = 3,
     type = "l",
     main = expression(paste(beta[0], " is outside range of observed data")),
     xlab = "x", 
     ylab = "log odds of y")

# simulate our observed data

x2 <- seq(5, 6, .1) # x2 (observed data points)

e <- rnorm(length(x2), 0, 1) # error term

y2 <- -x2 + 5 + e # generate y2

points(x2, y2, 
       col = michigancolors("blue"), 
       pch = 19)

```
  
    
4. Are there interactions (e.g. $x \times z$) in your model? Remember that when there is an interaction (e.g. $x \times z$) in a model, the coefficient for the main effect (e.g. $\beta x$) represents the coefficient for individuals for whom $z$ is 0. Perhaps $z$ should be centered? (Remember also that interactions in nonlinear models are *complicated* and require *special consideration*, an issue discussed elsewhere on this site.)
5. Is this an issue of *complete, or near complete separation*? i.e. one variable almost perfectly predicts the outcome? That too can lead to very large OR's or RR's.
6. Are there *very small cell (subsample) sizes*? Small sample sizes (cell sizes) can create anomalous estimates i.e. estimates from small samples (small table cells) can be very *noisy* estimates.

There may be other possibilities, but if one of the above strategies does not solve the problem, I would suggest deleting the variable from your model if possible.
