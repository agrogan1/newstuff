---
title: "Classification (Confusion) Matrices"
author: "Andy Grogan-Kaylor"
date: "today"
format:
  html:
    toc: true
    number-sections: true
    theme:
      light: yeti
      dark: vapor
    lightbox: true
    css: classification.css
  pdf:
    toc: true
    number-sections: true
bibliography: classification.bib
csl: apa.csl
---

# Introduction

Logistic regression might be considered to be a *classification algorithm*, as logistic regression provides predicted probabilities of an outcome. An important part of using any classification algorithm is evaluating the strength of the classification.

*Classification matrices*, sometimes (confusingly) called *confusion matrices*, provide a mechanism for evaluating many different statistical and machine learning methods.

# Data

We use data from @Hosmer2013 provided by Stata corporation.

```{r}
#| echo: false
#| output: false

library(Statamarkdown)

```

```{stata, collectcode=TRUE}

use https://www.stata-press.com/data/r18/lbw

```

# Describe The Data

```{stata}

describe // describe the data

```

# Use Logistic Regression To Predict Low Birthweight

We are going to use *logistic regression* to predict low birthweight. We will then use a *classification matrix* to study the accuracy of these predictions. 

```{stata, collectcode=TRUE}

logit low age lwt i.race smoke ptl ht ui, or // logistic regression

```

# Classification Matrix

The quantities of interest will often depend upon your discipline, and upon the specific research question. 

However, the **overall accuracy (correctly classified)**, **sensitivity**, **specificity** and **positive predictive value** will often be of general interest.

```{stata}

estat classification // classification matrix

```

# Reciever Operating Characteristic (ROC) Analysis

> "`lroc` graphs the ROC curve—a graph of sensitivity versus one minus specificity as the cutoff *c* is varied—and calculates the area under it. Sensitivity is the fraction of observed positive-outcome cases that are correctly classified; specificity is the fraction of observed negative-outcome cases that are correctly classified. When the purpose of the analysis is classification, you must choose a cutoff." [@StataCorp2025]

> "The curve starts at (0, 0), corresponding to *c* = 1, and continues to (1, 1), corresponding to *c*  = 0. A model with no predictive power would be a $45^{\circ}$ line. The greater the predictive power, the more bowed the curve, and hence the area beneath the curve is often used as a measure of the predictive power. A model with no predictive power has area 0.5; a perfect model has area 1." [@StataCorp2025]

```{stata}

lroc // ROC curve

graph export "ROC.png", width(1500) replace

```

![ROC curve](ROC.png)

# References



