---
title: "Non-Linear Models for Categorical Data Analysis"
subtitle: "Materials for a course on categorical data analysis."
author: 
  name: Andy Grogan-Kaylor 
  url: https://agrogan1.github.io/
  affiliation: 
    - name: University of Michigan
      url: https://umich.edu/
date: "today"
format:
  html: 
    toc: true
    number-sections: true
    theme:
      light: cosmo
      dark: vapor
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = FALSE,
                      message = FALSE,
                      warning = FALSE)

```

```{css, echo=FALSE}

blockquote {
  color: black;
  border-left: 2px solid gold; 
  padding: 0.5em 10px;
  }
  
```

```{r}

library(ggplot2) # beautiful graphs

library(patchwork) # weave ggplots together

library(dplyr) # data wrangling

library(plotly) # interactive graphs

library(knitr) # Rmarkdown

library(rgl) # 3d graphics
 
library(rayshader) # rayshading

```


```{r}

N <- 10000

x1 <- runif(N, -10, 10)

x2 <- runif(N, -10, 10)

y <- exp(x1 + x2)/(1 + exp(x1 + x2))

myprobability <- round(y, digits = 5)

# foundational logistic curve

p0 <- ggplot(data = NULL,
             aes(x = x1,
             y = x2,
             color = myprobability)) + 
  geom_point() +
  scale_color_viridis_c(name = "probability") +
  theme_minimal() + 
  theme(legend.position = "none",
        panel.background = element_rect(fill="white"),
        plot.background = element_rect(fill="white"))

# logistic curve

p1 <- p0 + 
  labs(title = "Logistic Curve",
       x = "x",
       y = "probability") 

# ggplotly(p1)

# ggsave(p1 + 
#          theme(title = element_text(size = rel(.5)),
#                axis.text.y = element_text(size = rel(.5))), 
#        filename = "logistic.png", 
#        height = 1.25)
# 
# ggsave(p1 + 
#          theme(aspect.ratio = 1),
#        filename = "logistic-square.png")
  
```


```{r, fig.cap="Manipulable Diagram of Logistic Surface"}

# knit_hooks$set(webgl = hook_webgl)

# rayshader::plot_gg(p1, zoom = .8) 

# rgl::plot3d(x = x1, y = x2, 
#             z = myprobability,
#             zlab = "probability",
#             col = myprobability + 1)


plotly::plot_ly(x =~x1, 
                y = ~x2, 
                z = ~myprobability, 
                type="scatter3d", 
                mode= "markers",
                marker = list(color = ~myprobability, 
                          colorbar = list(title = "probability"),
                          colorscale='Viridis',
                          showscale = TRUE),
                hovertemplate = paste('x1: %{x}',
                                  'x2: %{y}',
                                  'probability: %{z}',
                                  sep = "\n")) %>% 
  layout(scene = list(xaxis = list(title = 'x1'),
                      yaxis = list(title = 'x2'),
                      zaxis = list(title = 'probability'),
                      camera = list(eye = list(x = 1.5, 
                                               y = -1.5, 
                                               z = .5))))


# rglwidget()
 
```

```{r, eval=FALSE}

rayshader::plot_gg(p1, zoom = .8) %>%
  render_movie(filename = "logistic",
               type = "orbit",
               frames = 360,
               fps = 30)

```

```{r, eval=FALSE}

p1A <- p0 + p0 +
   plot_annotation(title = "Multinomial Logistic Curve")

```

```{r, eval=FALSE}

y2 <- round(pnorm(x), digits = 5)

p2 <- ggplot(data = NULL,
             aes(x = x,
             y = y2,
             color = y2)) + 
  geom_point() +
  scale_color_viridis_c(name = "probability") +
  labs(title = "Probit Curve",
       x = "x",
       y = "probability") +
  theme_minimal() + 
  theme(legend.position = "none",
        panel.background = element_rect(fill="white"),
        plot.background = element_rect(fill="white"))

p2
  
```

```{r, eval=FALSE}

rayshader::plot_gg(p2, zoom = .8) %>%
  render_movie(filename = "probit",
               type = "orbit",
               frames = 360,
               fps = 30)

```

```{r, eval=FALSE}

x3 <- rnbinom(10000, mu = 4, size = 1)

mydata <- data.frame(x3)

p3 <- mydata %>%
  count(x3) %>%
  ggplot(aes(x = x3,
             y = n,
             color = n)) + 
  geom_point() +
  scale_color_viridis_c() +
  labs(title = "Negative Binomial \nDistribution",
       x = "events",
       y = "count") +
  theme_minimal() +
  theme(legend.position = "none",
        panel.background = element_rect(fill="white"),
        plot.background = element_rect(fill="white"))

p3

```

```{r, eval=FALSE}

y3 <- .01 * exp(x)

p4 <- ggplot(data = NULL,
             aes(x = x,
             y = y3,
             color = y3)) + 
  geom_point() +
  scale_color_viridis_c() +
  labs(title = "Negative Binomial \nCurve",
       x = "x",
       y = "count") +
  theme_minimal() +
  theme(legend.position = "none",
        panel.background = element_rect(fill="white"),
        plot.background = element_rect(fill="white"))

p4
  
```


```{r, eval=FALSE}

rayshader::plot_gg(p3, zoom = .8) %>%
  render_movie(filename = "negative-binomial-distribution",
               type = "orbit",
               frames = 360,
               fps = 30)


```

```{r, eval=FALSE}

rayshader::plot_gg(p4, zoom = .8) %>%
  render_movie(filename = "negative-binomial",
               type = "orbit",
               frames = 360,
               fps = 30)

```

```{r, eval=FALSE}

save(x, y, myprobability, y2, y3, x3,
     p1, p2, p3, p4,
     file = "glm.RData")

```

> <span style="background-color:yellow">Instruction will be conducted in Stata, so basic knowledge of descriptive statistics and OLS in Stata is a prerequisite.</span>

> <span style="background-color: #FFFF00">Stata will be the statistical software employed in this course, and students will need access to Stata to participate. You will need to already have Stata, to purchase Stata from [https://www.stata.com/](https://www.stata.com/), or to use [https://its.umich.edu/computing/computers-software/virtual-sites](https://its.umich.edu/computing/computers-software/virtual-sites) to access Stata.</mark>

::: {.column-margin}
Our organizing question: "What is the chance that bad thing *x* will happen? What is the chance that good thing *y* will happen?
:::

> Lecture slides and handouts are [here](./README.html), and are free to share and download as long as you cite their source.

::: {.column-margin}
Because so many of the outcomes we study are so important--and are often unequally allocated--we want to make sure our answers are as precise, and as close to correct, as we can make them.
:::

```{r}
#| fig-cap: "The Nautilus Shell: Simple seeming questions contain hidden complexities."
#| column: margin

knitr::include_graphics("nautilus-new.png")

```

::: {.column-margin}
Failure to understand some of these hidden complexities may lead to providing *very* wrong answers.
:::

Researchers are most commonly aware of methods that are suitable for continuous dependent variables (e.g. mental health scores), such as the use of ordinary least squares regression. However, many outcomes of interest to social workers, and other social researchers, are decidedly not continuous, but are dichotomous or binary in nature, often representing important life events: born; died; entered the program; left the program; received a particular mental or physical health diagnosis; maltreatment or adverse event occurred; voted for a particular candidate or position; conflict or protest began; conflict or protest ended[^discuss]. These outcomes are often unequally allocated, represent disparities, are important policy or intervention outcomes, or some combination of all of these. Many researchers are familiar with the basics of logistic regression, yet do not have a grounding in some of the intricacies of logistic regression, such as generating predicted probabilities, visualizing these predicted probabilities, or using interaction terms in a categorical model, which can lead to clearer and more accurate reporting of results. Thus, proper use of these models may have substantive implications for research on disparities and inequalities as well as research on the outcomes of intervention or policy.

> In this course I try to thread the needle between exploring the statistical intricacies of these models, and discussing how a better understanding of categorical data analysis can help us make more accurate conclusions about the substantive issues that we care about.

Further, the basic logistic regression model serves as the foundation for a wide variety of more advanced statistical approaches that can help advance social research. Study of the logistic regression model can lead to variations of logistic regression such as logistic regression for ordered variables, or multinomial logistic regression where there are more than two categories of the outcome variable (e.g. multiple forms of family violence). An understanding of logistic regression also helps to motivate understanding of models for count data such as the Poisson and negative binomial model suitable for studying counts of events such as incidence of disease or incidence of violence. Lastly, categorical data models serve as the foundation for event history models that are used to study the timing of events, such as the timing of program entry, program departure, receipt of a diagnosis, or the timing of conflict or protest.

[^discuss]: I do not have data sets readily available on all of these issues, but we can certainly *discuss* how the models discussed in this course might be applied to any of these issues.













